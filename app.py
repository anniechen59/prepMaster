import streamlit as st
import os
import json
import time
import wave
import sys
import base64
import streamlit.components.v1 as components

# ==========================================
# 0. Module Imports
# ==========================================
sys.path.append(os.getcwd())
try:
    from utils.pdf_utils import process_pdf_for_pipeline
    from utils.whisper_utils import run_whisper_analysis
    from data.slides.keywords_expander import run_keyword_expansion
    from analysis.matcher import run_comprehensive_analysis
    from ai.coach import generate_coach_feedback
except ImportError as e:
    st.error(f"âŒ Module Import Failed: {e}")

# ==========================================
# 1. Configuration & Styling
# ==========================================
st.set_page_config(page_title="PrepMaster AI - Auto Studio", layout="wide")

st.markdown("""
    <style>
    .stImage > img { max-height: 500px; object-fit: contain; border-radius: 10px; border: 1px solid #ddd; }
    .stMetric { background-color: #f8f9fb; padding: 15px; border-radius: 10px; }
    .report-container { background-color: #fdfdfd; padding: 25px; border-radius: 15px; border-left: 10px solid #FF4B4B; border: 1px solid #eee; margin-top: 20px; }
    .ignore-btn { color: #ff4b4b; cursor: pointer; border: 1px solid #ff4b4b; padding: 2px 5px; border-radius: 5px; font-size: 0.8em; }
    </style>
    """, unsafe_allow_html=True)

TEMP_DIR = "temp_data"
os.makedirs(TEMP_DIR, exist_ok=True)

# Pipeline Paths
PATH_PDF = os.path.join(TEMP_DIR, "presentation.pdf")
PATH_AUDIO_WAV = os.path.join(TEMP_DIR, "audio.wav")
PATH_TIMING = os.path.join(TEMP_DIR, "timing.json")
PATH_SLIDES_JSON = os.path.join(TEMP_DIR, "slides.json")
PATH_SLIDES_EXP = os.path.join(TEMP_DIR, "slides_expanded.json")
PATH_WHISPER_OUT = os.path.join(TEMP_DIR, "whisper_output.json")
PATH_FINAL_REPORT = os.path.join(TEMP_DIR, "final_report.json")
PATH_FEEDBACK_MD = os.path.join(TEMP_DIR, "feedback.md")

# Initialize Session State
if 'page_index' not in st.session_state: st.session_state.page_index = 0
if 'slide_timestamps' not in st.session_state: st.session_state.slide_timestamps = [] 
if 'practice_started' not in st.session_state: st.session_state.practice_started = False
if 'start_time_epoch' not in st.session_state: st.session_state.start_time_epoch = 0.0
if 'pdf_images' not in st.session_state: st.session_state.pdf_images = []
if 'ignored_keywords' not in st.session_state: st.session_state.ignored_keywords = set()

# ==========================================
# 2. ğŸ”¥ Auto-Trigger Workflow (Stage 1)
# ==========================================
def run_auto_analysis_stage_1(audio_file):
    """Trigger basic analysis with time calibration"""
    with st.status("ğŸš€ AI analyzing your performance...", expanded=True) as status:
        # 1. å„²å­˜éŸ³æª”ä¸¦ç²å–ç¸½é•·åº¦
        with open(PATH_AUDIO_WAV, "wb") as f:
            f.write(audio_file.read())
        
        with wave.open(PATH_AUDIO_WAV, 'rb') as wf:
            total_duration = wf.getnframes() / wf.getframerate()

        # --- æ ¸å¿ƒä¿®æ­£ï¼šè¨ˆç®—éŒ„éŸ³é–‹å§‹çš„åç§»é‡ ---
        # ä½ çš„ slide_timestamps æ˜¯ç›¸å°æ–¼ start_time_epoch çš„
        # æˆ‘å€‘å‡è¨­éŒ„éŸ³æ˜¯åœ¨æœ€å¾Œä¸€å€‹æ­¥é©Ÿæ‰ç™¼ç”Ÿçš„
        # éŒ„éŸ³çµ„ä»¶è¢«è§¸ç™¼çš„æ™‚é–“é€šå¸¸æ¥è¿‘ç•¶ä¸‹ time.time()
        
        current_time = time.time()
        # é€™æ˜¯éŒ„éŸ³å®Œæˆçš„æ™‚åˆ»ï¼ŒéŒ„éŸ³é•·åº¦æ˜¯ total_duration
        # æ‰€ä»¥éŒ„éŸ³é–‹å§‹çš„æ™‚åˆ»ï¼ˆç›¸å°æ–¼ start_time_epochï¼‰æ˜¯ï¼š
        audio_start_in_session = (current_time - st.session_state.start_time_epoch) - total_duration

        final_timings = []
        ts = st.session_state.slide_timestamps

        for i in range(len(ts)):
            if ts[i]['page'] == "END":
                continue

            # å°‡ç¿»é æ™‚é–“æ ¡æº–åˆ°éŒ„éŸ³æª”çš„æ™‚é–“è»¸ä¸Š
            # éŒ„éŸ³æª”æ™‚é–“ = ç¿»é æ™‚åˆ» - éŒ„éŸ³é–‹å§‹æ™‚åˆ»
            raw_start = ts[i]['time'] - audio_start_in_session
            
            # ç¢ºä¿ç¬¬ä¸€é è‡³å°‘å¾ 0.0 é–‹å§‹ï¼Œä¸”ä¸ç‚ºè² æ•¸
            start_time = max(0.0, round(raw_start, 2))

            if i + 1 < len(ts) and ts[i+1]['page'] != "END":
                end_time = round(ts[i+1]['time'] - audio_start_in_session, 2)
            else:
                end_time = round(total_duration, 2)

            # --- ä¿è­·æ©Ÿåˆ¶ ---
            # 1. é˜²æ­¢çµæŸæ™‚é–“è¶…ééŸ³æª”ç¸½é•·
            end_time = min(end_time, round(total_duration, 2))
            # 2. é˜²æ­¢æ™‚é–“å€’é€€æˆ–éçŸ­
            if end_time <= start_time:
                end_time = start_time + 0.1

            final_timings.append({
                "page_index": ts[i]['page'],
                "start_time": start_time,
                "end_time": end_time
            })

        # å¦‚æœæ ¡æº–å¾Œç¬¬ä¸€é ä¸æ˜¯å¾ 0 é–‹å§‹ï¼ˆé€šå¸¸æ˜¯å› ç‚ºéŒ„éŸ³é–‹å§‹å¾—æ¯”ç¬¬ä¸€é æ™šï¼‰
        # å¼·åˆ¶å°‡ç¬¬ä¸€é  start_time è¨­ç‚º 0ï¼Œç¢ºä¿åˆ†æå®Œæ•´æ€§
        if final_timings:
            final_timings[0]['start_time'] = 0.0

        with open(PATH_TIMING, 'w', encoding='utf-8') as f:
            json.dump(final_timings, f, indent=2)

        # 2. åŸ·è¡Œå¾ŒçºŒæµç¨‹
        run_whisper_analysis(PATH_AUDIO_WAV, PATH_SLIDES_JSON, PATH_WHISPER_OUT)
        run_keyword_expansion(PATH_SLIDES_JSON, PATH_SLIDES_EXP)
        run_comprehensive_analysis(PATH_SLIDES_EXP, PATH_WHISPER_OUT, PATH_TIMING, PATH_AUDIO_WAV, PATH_FINAL_REPORT)
        
        if os.path.exists(PATH_FEEDBACK_MD): os.remove(PATH_FEEDBACK_MD)
        
        st.session_state.practice_started = False
        status.update(label="Analysis Complete! Timestamps Calibrated.", state="complete")
        st.toast("Ready! Audio and Slides are now synchronized.")
# ==========================================
# 3. Main UI Layout
# ==========================================
st.title("ğŸ¤ PrepMaster AI Studio")

if not st.session_state.pdf_images:
    uploaded_pdf = st.file_uploader("Upload Presentation PDF to begin", type="pdf")
    if uploaded_pdf:
        with open(PATH_PDF, "wb") as f: f.write(uploaded_pdf.read())
        slide_data = process_pdf_for_pipeline(PATH_PDF, os.path.join(TEMP_DIR, "images"), PATH_SLIDES_JSON)
        st.session_state.pdf_images = [item['image_path'] for item in slide_data]
        st.rerun()
else:
    col_left, col_right = st.columns([7, 3], gap="large")

    with col_right:
        st.subheader("ğŸ“Š Session Control")
        
        if not st.session_state.practice_started:
            st.info("ğŸ’¡ **Ready?** Click 'Start' then use the recorder.")
            if st.button("ğŸš€ Start Session", type="primary", use_container_width=True):
                st.session_state.practice_started = True
                st.session_state.start_time_epoch = time.time()
                st.session_state.slide_timestamps = [{"page": 0, "time": 0.0}]
                st.session_state.ignored_keywords = set() # Reset ignore list
                st.rerun()
        else:
            st.success("ğŸ”´ **Session Live**")
            audio_data = st.audio_input("Record your presentation")
            if audio_data:
                run_auto_analysis_stage_1(audio_data)
                st.rerun()
            
            elapsed = time.time() - st.session_state.start_time_epoch
            st.metric("Elapsed Time", f"{elapsed:.1f}s")

    with col_left:
        curr = st.session_state.page_index
        total = len(st.session_state.pdf_images)
        st.image(st.session_state.pdf_images[curr], use_container_width=True)
        
        c1, c2 = st.columns([1, 1])
        with c1:
            if st.button("â¬…ï¸ Prev", disabled=curr == 0, use_container_width=True):
                st.session_state.page_index -= 1
                st.rerun()
        with c2:
            if st.button("Next â¡ï¸", disabled=curr == total - 1, use_container_width=True, type="secondary"):
                if st.session_state.practice_started:
                    st.session_state.slide_timestamps.append({
                        "page": curr + 1, "time": time.time() - st.session_state.start_time_epoch
                    })
                st.session_state.page_index += 1
                st.rerun()

    # ==========================================
    # 4. Review Section (Interactive Calibration)
    # ==========================================
    if os.path.exists(PATH_FINAL_REPORT) and not st.session_state.practice_started:
        st.divider()
        st.subheader("ğŸ§ 1. Review & Calibrate Keywords")
        st.caption("Instructions: Click 'Ignore' on keywords that were not intended to be spoken (e.g., student IDs, course codes).")
        
        with open(PATH_FINAL_REPORT, 'r', encoding='utf-8') as f:
            final_reports = json.load(f)
        
        current_idx = st.session_state.page_index
        current_data = final_reports[current_idx]
        start_t, end_t = current_data['start_time'], current_data['end_time']

        rev_left, rev_right = st.columns([1, 1], gap="large")
        
        with rev_left:
            st.image(st.session_state.pdf_images[current_idx], use_container_width=True)
            selected_page_num = st.slider("Quick Navigate", 1, len(final_reports), current_idx + 1, key="review_slider")
            if selected_page_num - 1 != current_idx:
                st.session_state.page_index = selected_page_num - 1
                st.rerun()

            # Audio Segment Player
            with open(PATH_AUDIO_WAV, "rb") as f:
                audio_url = f"data:audio/wav;base64,{base64.b64encode(f.read()).decode()}"
            audio_js = f"""
                <div style="background: #f8f9fa; padding: 10px; border-radius: 8px; border: 1px solid #ddd;">
                    <audio id="audio-player" controls style="width: 100%;"><source src="{audio_url}" type="audio/wav"></audio>
                </div>
                <script>
                    var player = document.getElementById('audio-player');
                    player.currentTime = {start_t};
                    player.ontimeupdate = function() {{ if (player.currentTime >= {end_t}) {{ player.pause(); player.currentTime = {end_t}; }} }};
                </script>"""
            components.html(audio_js, height=100)

        with rev_right:
            st.markdown(f"### ğŸ“ Slide {current_idx + 1} Insights")
            
            # Transcript Display
            transcript = current_data['content_analysis'].get('transcript_extract', '')
            st.info(transcript if transcript.strip() else "âš ï¸ No speech detected.")
            
            # Interactive Keyword Section
            st.markdown("**ğŸ¯ Content Calibration:**")
            covered = current_data['content_analysis'].get('covered_keywords', [])
            raw_missed = current_data['content_analysis'].get('missed_keywords', [])
            
            # Filter missed based on ignore list
            active_missed = [k for k in raw_missed if k not in st.session_state.ignored_keywords]
            
            c_cov, c_miss = st.columns(2)
            with c_cov:
                st.success(f"âœ… Covered ({len(covered)})")
                for k in covered: st.caption(f"â€¢ {k}")
            
            with c_miss:
                st.error(f"âŒ Missed ({len(active_missed)})")
                for k in active_missed:
                    # Individual Ignore Buttons
                    if st.button(f"Ignore '{k}'", key=f"ign_{k}_{current_idx}", type="secondary", use_container_width=True):
                        st.session_state.ignored_keywords.add(k)
                        st.rerun()
            
            # Dynamic Score Calculation
            all_keys = covered + raw_missed
            remaining_keys = [k for k in all_keys if k not in st.session_state.ignored_keywords]
            total_valid = len(remaining_keys)
            adj_score = (len(covered) / total_valid * 100) if total_valid > 0 else 100.0
            
            st.divider()
            st.metric("Adjusted Page Score", f"{adj_score:.1f}%", help="Calculated based on non-ignored keywords.")

        # ==========================================
        # 5. Final Coach Trigger (Stage 2)
        # ==========================================
        # UI Button logic for Stage 2 (Final Diagnosis)
        st.divider()
        st.subheader("ğŸš€ 2. Final Diagnosis")
        
        # æª¢æŸ¥å ±å‘Šæ˜¯å¦å·²å­˜åœ¨
        report_exists = os.path.exists(PATH_FEEDBACK_MD)

        if not report_exists:
            # ç¬¬ä¸€éšæ®µï¼šå°šæœªç”¢ç”Ÿå ±å‘Š
            if st.button("âœ¨ Generate AI Coach Report", type="primary", use_container_width=True):
                with st.spinner("PrepMaster AI is finalizing your executive report..."):
                    # ç¢ºä¿å°‡å¿½ç•¥æ¸…å–®å‚³å…¥å¾Œç«¯è™•ç†
                    generate_coach_feedback(
                        PATH_FINAL_REPORT, 
                        PATH_FEEDBACK_MD, 
                        ignored_keywords=st.session_state.ignored_keywords
                    )
                    st.rerun()
        else:
            # ç¬¬äºŒéšæ®µï¼šå ±å‘Šå·²ç”¢ç”Ÿï¼Œé¡¯ç¤ºå ±å‘Šèˆ‡ã€Œé‡æ–°ç”¢ç”Ÿã€æŒ‰éˆ•
            with open(PATH_FEEDBACK_MD, 'r', encoding='utf-8') as f:
                st.markdown(f'<div class="report-container">{f.read()}</div>', unsafe_allow_html=True)
            
            st.write("") # å¢åŠ ä¸€é»é–“è·
            
            # ä½¿ç”¨å…©æ¬„ä½ˆå±€ï¼Œè®“é‡æ–°ç”¢ç”Ÿçš„æŒ‰éˆ•ä¸è¦ä½”æ»¿æ•´å€‹ç•«é¢ï¼Œçœ‹èµ·ä¾†æ¯”è¼ƒç²¾ç·»
            c_bot1, c_bot2 = st.columns([2, 1])
            with c_bot2:
                if st.button("ğŸ”„ Update & Regenerate", use_container_width=True):
                    # åˆªé™¤èˆŠå ±å‘Šä¸¦é‡æ–°åŸ·è¡Œï¼ŒæœƒæŠ“å–æœ€æ–°çš„å¿½ç•¥æ¸…å–®
                    os.remove(PATH_FEEDBACK_MD)
                    st.rerun()